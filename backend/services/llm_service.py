"""HealthMitra Scan â€“ LLM Service (Real Ollama Integration)"""
import json
import logging

logger = logging.getLogger(__name__)

# Try to import ollama SDK
try:
    import ollama
    OLLAMA_AVAILABLE = True
except ImportError:
    OLLAMA_AVAILABLE = False
    logger.warning("ollama package not installed. Using fallback responses.")


# â”€â”€ Fallback responses when Ollama is not available â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
FALLBACK_EXPLANATIONS = {
    "en": {
        "high": "âš ï¸ This report shows several concerning values that need immediate medical attention. "
                "Your blood sugar levels are significantly elevated, indicating poorly controlled diabetes. "
                "The lipid profile shows high cholesterol which increases cardiovascular risk. "
                "Kidney function markers are above normal range, suggesting early kidney stress. "
                "Please consult your doctor immediately for medication adjustment and lifestyle changes.",
        "moderate": "ðŸ“‹ This report shows some values that need attention but are not immediately dangerous. "
                    "Your blood sugar is slightly elevated, placing you in the pre-diabetic range. "
                    "Some vitamin levels are low, which can cause fatigue and weakness. "
                    "Thyroid function may need monitoring. "
                    "Recommend dietary improvements, regular exercise, and follow-up tests in 3 months.",
        "low": "âœ… Great news! Your report shows mostly normal values. "
               "All major blood markers including blood sugar, cholesterol, kidney and liver function "
               "are within healthy ranges. Continue maintaining your healthy lifestyle with balanced "
               "diet and regular exercise. Recommended routine check-up in 6-12 months."
    },
    "hi": {
        "high": "âš ï¸ à¤‡à¤¸ à¤°à¤¿à¤ªà¥‹à¤°à¥à¤Ÿ à¤®à¥‡à¤‚ à¤•à¤ˆ à¤šà¤¿à¤‚à¤¤à¤¾à¤œà¤¨à¤• à¤®à¤¾à¤¨ à¤¹à¥ˆà¤‚ à¤œà¤¿à¤¨ à¤ªà¤° à¤¤à¥à¤°à¤‚à¤¤ à¤§à¥à¤¯à¤¾à¤¨ à¤¦à¥‡à¤¨à¥‡ à¤•à¥€ à¤œà¤¼à¤°à¥‚à¤°à¤¤ à¤¹à¥ˆà¥¤ "
               "à¤†à¤ªà¤•à¤¾ à¤¬à¥à¤²à¤¡ à¤¶à¥à¤—à¤° à¤¬à¤¹à¥à¤¤ à¤…à¤§à¤¿à¤• à¤¹à¥ˆ, à¤œà¥‹ à¤¡à¤¾à¤¯à¤¬à¤¿à¤Ÿà¥€à¤œ à¤•à¤¾ à¤¸à¤‚à¤•à¥‡à¤¤ à¤¹à¥ˆà¥¤ "
               "à¤•à¥‹à¤²à¥‡à¤¸à¥à¤Ÿà¥à¤°à¥‰à¤² à¤¬à¤¢à¤¼à¤¾ à¤¹à¥à¤† à¤¹à¥ˆ à¤œà¤¿à¤¸à¤¸à¥‡ à¤¹à¥ƒà¤¦à¤¯ à¤°à¥‹à¤— à¤•à¤¾ à¤–à¤¤à¤°à¤¾ à¤¬à¤¢à¤¼ à¤œà¤¾à¤¤à¤¾ à¤¹à¥ˆà¥¤ "
               "à¤•à¤¿à¤¡à¤¨à¥€ à¤•à¥€ à¤•à¤¾à¤°à¥à¤¯à¤ªà¥à¤°à¤£à¤¾à¤²à¥€ à¤ªà¤° à¤­à¥€ à¤ªà¥à¤°à¤­à¤¾à¤µ à¤¦à¤¿à¤– à¤°à¤¹à¤¾ à¤¹à¥ˆà¥¤ "
               "à¤•à¥ƒà¤ªà¤¯à¤¾ à¤¤à¥à¤°à¤‚à¤¤ à¤…à¤ªà¤¨à¥‡ à¤¡à¥‰à¤•à¥à¤Ÿà¤° à¤¸à¥‡ à¤®à¤¿à¤²à¥‡à¤‚ à¤”à¤° à¤¦à¤µà¤¾à¤‡à¤¯à¥‹à¤‚ à¤®à¥‡à¤‚ à¤¬à¤¦à¤²à¤¾à¤µ à¤•à¤°à¤µà¤¾à¤à¤‚à¥¤",
        "moderate": "ðŸ“‹ à¤‡à¤¸ à¤°à¤¿à¤ªà¥‹à¤°à¥à¤Ÿ à¤®à¥‡à¤‚ à¤•à¥à¤› à¤®à¤¾à¤¨ à¤¸à¤¾à¤®à¤¾à¤¨à¥à¤¯ à¤¸à¥‡ à¤¥à¥‹à¤¡à¤¼à¥‡ à¤…à¤§à¤¿à¤• à¤¹à¥ˆà¤‚ à¤²à¥‡à¤•à¤¿à¤¨ à¤¤à¥à¤°à¤‚à¤¤ à¤–à¤¤à¤°à¤¨à¤¾à¤• à¤¨à¤¹à¥€à¤‚ à¤¹à¥ˆà¤‚à¥¤ "
                    "à¤¬à¥à¤²à¤¡ à¤¶à¥à¤—à¤° à¤¥à¥‹à¤¡à¤¼à¤¾ à¤¬à¤¢à¤¼à¤¾ à¤¹à¥à¤† à¤¹à¥ˆ, à¤œà¥‹ à¤ªà¥à¤°à¥€-à¤¡à¤¾à¤¯à¤¬à¤¿à¤Ÿà¥€à¤œ à¤•à¥€ à¤¶à¥à¤°à¥‡à¤£à¥€ à¤®à¥‡à¤‚ à¤†à¤¤à¤¾ à¤¹à¥ˆà¥¤ "
                    "à¤•à¥à¤› à¤µà¤¿à¤Ÿà¤¾à¤®à¤¿à¤¨ à¤•à¥€ à¤•à¤®à¥€ à¤¹à¥ˆ à¤œà¤¿à¤¸à¤¸à¥‡ à¤¥à¤•à¤¾à¤¨ à¤¹à¥‹ à¤¸à¤•à¤¤à¥€ à¤¹à¥ˆà¥¤ "
                    "à¤–à¤¾à¤¨-à¤ªà¤¾à¤¨ à¤®à¥‡à¤‚ à¤¸à¥à¤§à¤¾à¤°, à¤¨à¤¿à¤¯à¤®à¤¿à¤¤ à¤µà¥à¤¯à¤¾à¤¯à¤¾à¤® à¤”à¤° 3 à¤®à¤¹à¥€à¤¨à¥‡ à¤¬à¤¾à¤¦ à¤¦à¥‹à¤¬à¤¾à¤°à¤¾ à¤œà¤¾à¤‚à¤š à¤•à¤°à¤µà¤¾à¤à¤‚à¥¤",
        "low": "âœ… à¤¬à¤¹à¥à¤¤ à¤…à¤šà¥à¤›à¥€ à¤–à¤¬à¤°! à¤†à¤ªà¤•à¥€ à¤°à¤¿à¤ªà¥‹à¤°à¥à¤Ÿ à¤²à¤—à¤­à¤— à¤¸à¤­à¥€ à¤®à¤¾à¤¨ à¤¸à¤¾à¤®à¤¾à¤¨à¥à¤¯ à¤¶à¥à¤°à¥‡à¤£à¥€ à¤®à¥‡à¤‚ à¤¹à¥ˆà¤‚à¥¤ "
              "à¤¬à¥à¤²à¤¡ à¤¶à¥à¤—à¤°, à¤•à¥‹à¤²à¥‡à¤¸à¥à¤Ÿà¥à¤°à¥‰à¤², à¤•à¤¿à¤¡à¤¨à¥€ à¤”à¤° à¤²à¤¿à¤µà¤° à¤•à¥€ à¤•à¤¾à¤°à¥à¤¯à¤ªà¥à¤°à¤£à¤¾à¤²à¥€ à¤¸à¤¬ à¤ à¥€à¤• à¤¹à¥ˆà¥¤ "
              "à¤…à¤ªà¤¨à¥€ à¤¸à¥à¤µà¤¸à¥à¤¥ à¤œà¥€à¤µà¤¨à¤¶à¥ˆà¤²à¥€ à¤¬à¤¨à¤¾à¤ à¤°à¤–à¥‡à¤‚à¥¤ 6-12 à¤®à¤¹à¥€à¤¨à¥‡ à¤¬à¤¾à¤¦ à¤¨à¤¿à¤¯à¤®à¤¿à¤¤ à¤œà¤¾à¤‚à¤š à¤•à¤°à¤µà¤¾à¤à¤‚à¥¤"
    }
}

FALLBACK_QA = {
    "en": "Based on your question, I recommend consulting with a healthcare professional for personalized advice. "
          "In general, maintaining a balanced diet, regular exercise, adequate sleep, and stress management "
          "are key pillars of good health. If you have specific symptoms, please describe them in detail "
          "so I can provide more targeted guidance.",
    "hi": "à¤†à¤ªà¤•à¥‡ à¤¸à¤µà¤¾à¤² à¤•à¥‡ à¤†à¤§à¤¾à¤° à¤ªà¤°, à¤®à¥ˆà¤‚ à¤µà¥à¤¯à¤•à¥à¤¤à¤¿à¤—à¤¤ à¤¸à¤²à¤¾à¤¹ à¤•à¥‡ à¤²à¤¿à¤ à¤¸à¥à¤µà¤¾à¤¸à¥à¤¥à¥à¤¯ à¤µà¤¿à¤¶à¥‡à¤·à¤œà¥à¤ž à¤¸à¥‡ à¤®à¤¿à¤²à¤¨à¥‡ à¤•à¥€ à¤¸à¤¿à¤«à¤¾à¤°à¤¿à¤¶ à¤•à¤°à¤¤à¤¾ à¤¹à¥‚à¤‚à¥¤ "
          "à¤¸à¤¾à¤®à¤¾à¤¨à¥à¤¯ à¤¤à¥Œà¤° à¤ªà¤°, à¤¸à¤‚à¤¤à¥à¤²à¤¿à¤¤ à¤†à¤¹à¤¾à¤°, à¤¨à¤¿à¤¯à¤®à¤¿à¤¤ à¤µà¥à¤¯à¤¾à¤¯à¤¾à¤®, à¤ªà¤°à¥à¤¯à¤¾à¤ªà¥à¤¤ à¤¨à¥€à¤‚à¤¦ à¤”à¤° à¤¤à¤¨à¤¾à¤µ à¤ªà¥à¤°à¤¬à¤‚à¤§à¤¨ à¤…à¤šà¥à¤›à¥‡ à¤¸à¥à¤µà¤¾à¤¸à¥à¤¥à¥à¤¯ à¤•à¥‡ "
          "à¤®à¥à¤–à¥à¤¯ à¤†à¤§à¤¾à¤° à¤¹à¥ˆà¤‚à¥¤ à¤¯à¤¦à¤¿ à¤†à¤ªà¤•à¥‡ à¤•à¥‹à¤ˆ à¤µà¤¿à¤¶à¥‡à¤· à¤²à¤•à¥à¤·à¤£ à¤¹à¥ˆà¤‚, à¤¤à¥‹ à¤•à¥ƒà¤ªà¤¯à¤¾ à¤µà¤¿à¤¸à¥à¤¤à¤¾à¤° à¤¸à¥‡ à¤¬à¤¤à¤¾à¤à¤‚à¥¤"
}


# â”€â”€ Ollama LLM calls â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _check_ollama_running() -> bool:
    """Check if Ollama server is running and accessible."""
    if not OLLAMA_AVAILABLE:
        return False
    try:
        ollama.list()
        return True
    except Exception:
        return False


def _get_available_model() -> str | None:
    """Get the first available model from Ollama."""
    try:
        models = ollama.list()
        if models and hasattr(models, 'models') and len(models.models) > 0:
            return models.models[0].model
        return None
    except Exception:
        return None


def explain_report(ocr_text: str, risk_level: str = "moderate", language: str = "en") -> str:
    """
    Explain a medical report in simple language.
    Uses Ollama if available, falls back to pre-built responses.
    """
    if _check_ollama_running():
        model = _get_available_model()
        if model:
            try:
                lang_instruction = "in simple English" if language == "en" else "in simple Hindi (Devanagari script)"

                prompt = f"""You are HealthMitra, a caring and knowledgeable AI health assistant for Indian patients.
Analyze this medical report and explain it {lang_instruction} that a common person can understand.

Instructions:
- Identify abnormal values and explain what they mean
- Use simple, non-technical language
- Mention which values are concerning and which are normal
- Give a brief health recommendation
- Use relevant emojis for visual clarity
- Keep the response concise (200-300 words)

Medical Report:
{ocr_text}

Provide your explanation:"""

                response = ollama.chat(
                    model=model,
                    messages=[{"role": "user", "content": prompt}],
                    options={"temperature": 0.7, "num_predict": 500}
                )
                return response["message"]["content"]
            except Exception as e:
                logger.error(f"Ollama error: {e}")

    # Fallback
    return FALLBACK_EXPLANATIONS.get(language, FALLBACK_EXPLANATIONS["en"]).get(
        risk_level, FALLBACK_EXPLANATIONS["en"]["moderate"]
    )


def answer_health_question(question: str, language: str = "en", context: str = "") -> str:
    """
    Answer a health-related question using LLM.
    Uses Ollama if available, falls back to generic response.
    """
    if _check_ollama_running():
        model = _get_available_model()
        if model:
            try:
                lang_instruction = "in English" if language == "en" else "in Hindi (Devanagari script)"
                context_text = f"\nPatient context: {context}" if context else ""

                prompt = f"""You are HealthMitra, a caring AI health assistant for Indian patients.
Answer the following health question {lang_instruction} in a helpful, empathetic manner.
{context_text}

Important guidelines:
- Give practical, actionable advice
- Mention when to see a doctor
- Reference Indian dietary habits and lifestyle where relevant
- Keep response concise (150-250 words)
- Use emojis for visual clarity
- Always add a disclaimer that this is AI advice, not a replacement for a real doctor

Question: {question}

Your answer:"""

                response = ollama.chat(
                    model=model,
                    messages=[{"role": "user", "content": prompt}],
                    options={"temperature": 0.7, "num_predict": 400}
                )
                return response["message"]["content"]
            except Exception as e:
                logger.error(f"Ollama error: {e}")

    # Fallback
    return FALLBACK_QA.get(language, FALLBACK_QA["en"])


def get_ollama_status() -> dict:
    """Get current Ollama/LLM status for system dashboard."""
    running = _check_ollama_running()
    model = _get_available_model() if running else None

    return {
        "ollama_installed": OLLAMA_AVAILABLE,
        "ollama_running": running,
        "model_loaded": model or "none",
        "status": "online" if running and model else "offline"
    }
